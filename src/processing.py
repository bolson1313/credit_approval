import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.preprocessing import LabelEncoder
from utils import parse_indices, get_numeric_columns, get_categorical_columns, safe_metric_delta

class ProcessingModule:
    def __init__(self):
        self.scalers = {
            'MinMaxScaler': MinMaxScaler,
            'StandardScaler': StandardScaler
        }
    
    def render(self, df: pd.DataFrame) -> pd.DataFrame:
        """Renderuje zakÅ‚adkÄ™ przetwarzania"""
        if df is None or df.empty:
            st.warning("Brak danych do przetwarzania.")
            return df if df is not None else pd.DataFrame()
            
        st.header("ðŸ”§ Przetwarzanie Danych")
        st.info("âš ï¸ Wszystkie zmiany bÄ™dÄ… zastosowane do gÅ‚Ã³wnego datasetu!")
        
        # Przechowujemy oryginalny stan dla porÃ³wnania
        original_df = df.copy()
        processed_df = df.copy()
        
        # Sekcje przetwarzania
        with st.expander("âœ‚ï¸ Ekstrakcja podtablic", expanded=False):
            new_df = self._handle_data_extraction(processed_df)
            if new_df is not None and not new_df.equals(processed_df):
                processed_df = new_df
                st.success("âœ… Zastosowano zmiany w ekstrakcji danych")
        
        with st.expander("ðŸ”„ ZastÄ™powanie wartoÅ›ci", expanded=False):
            new_df = self._handle_value_replacement(processed_df)
            if new_df is not None and not new_df.equals(processed_df):
                processed_df = new_df
                st.success("âœ… Zastosowano zastÄ™powanie wartoÅ›ci")
        
        with st.expander("ðŸ“ Skalowanie i standaryzacja", expanded=False):
            new_df = self._handle_scaling(processed_df)
            if new_df is not None and not new_df.equals(processed_df):
                processed_df = new_df
                st.success("âœ… Zastosowano skalowanie danych")
        
        with st.expander("ðŸ•³ï¸ ObsÅ‚uga brakujÄ…cych danych", expanded=False):
            new_df = self._handle_missing_data(processed_df)
            if new_df is not None and not new_df.equals(processed_df):
                processed_df = new_df
                st.success("âœ… Zastosowano obsÅ‚ugÄ™ brakujÄ…cych danych")
        
        with st.expander("ðŸ”‚ Usuwanie duplikatÃ³w", expanded=False):
            new_df = self._handle_duplicates(processed_df)
            if new_df is not None and not new_df.equals(processed_df):
                processed_df = new_df
                st.success("âœ… UsuniÄ™to duplikaty")
        
        with st.expander("ðŸ”¢ Kodowanie kolumn symbolicznych", expanded=False):
            new_df = self._handle_encoding(processed_df)
            if new_df is not None and not new_df.equals(processed_df):
                processed_df = new_df
                st.success("âœ… Zastosowano kodowanie kolumn")
        
        # PorÃ³wnanie przed/po
        if not processed_df.equals(original_df):
            self._show_comparison(original_df, processed_df)
        
        return processed_df
    
    def _handle_data_extraction(self, df: pd.DataFrame) -> pd.DataFrame:
        """ObsÅ‚uguje ekstrakcjÄ™ podtablic"""
        st.subheader("Ekstrakcja wierszy i kolumn")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Wiersze:**")
            action_rows = st.radio(
                "Akcja dla wierszy:",
                ["Brak zmian", "UsuÅ„ wybrane", "Zachowaj tylko wybrane"],
                key="rows_action"
            )
            
            # Input zawsze widoczny
            rows_input = st.text_input(
                "Podaj numery wierszy (np. 0,2,4 lub 0-4 lub 0,2-4,6):",
                key="rows_input",
                help="Numeracja od 0 (pierwszy wiersz to 0)",
                disabled=(action_rows == "Brak zmian")
            )
            
            if action_rows != "Brak zmian" and rows_input:
                if st.button("Zastosuj dla wierszy", key="apply_rows"):
                    # Parsuj indeksy (juÅ¼ 0-based)
                    indices = parse_indices(rows_input, len(df))
                    if indices:
                        if action_rows == "UsuÅ„ wybrane":
                            # UsuÅ„ wybrane indeksy
                            remaining_indices = [i for i in range(len(df)) if i not in indices]
                            df = df.iloc[remaining_indices]
                            # NIE resetuj indeksu - zachowaj oryginalne numerowanie
                            st.success(f"UsuniÄ™to {len(indices)} wierszy")
                        else:  # Zachowaj tylko wybrane
                            df = df.iloc[indices]
                            # NIE resetuj indeksu - zachowaj oryginalne numerowanie
                            st.success(f"Zachowano {len(indices)} wierszy")
        
        with col2:
            st.markdown("**Kolumny:**")
            action_cols = st.radio(
                "Akcja dla kolumn:",
                ["Brak zmian", "UsuÅ„ wybrane", "Zachowaj tylko wybrane"],
                key="cols_action"
            )
            
            if action_cols != "Brak zmian":
                selected_cols = st.multiselect(
                    "Wybierz kolumny:",
                    df.columns.tolist(),
                    key="selected_cols"
                )
                
                if selected_cols and st.button("Zastosuj dla kolumn", key="apply_cols"):
                    if action_cols == "UsuÅ„ wybrane":
                        df = df.drop(columns=selected_cols)
                        st.success(f"UsuniÄ™to {len(selected_cols)} kolumn")
                    else:  # Zachowaj tylko wybrane
                        df = df[selected_cols]
                        st.success(f"Zachowano {len(selected_cols)} kolumn")
        
        return df
    
    def _handle_value_replacement(self, df: pd.DataFrame) -> pd.DataFrame:
        """ObsÅ‚uguje zastÄ™powanie wartoÅ›ci"""
        st.subheader("ZastÄ™powanie wartoÅ›ci")
        
        tab1, tab2 = st.tabs(["Manual", "Automatyczne"])
        
        with tab1:
            st.markdown("**Edycja manualna:**")
            if st.checkbox("WÅ‚Ä…cz edycjÄ™ manualnÄ…", key="enable_manual_edit"):
                edited_df = st.data_editor(
                    df,
                    use_container_width=True,
                    height=300,
                    key="manual_editor"
                )
                if st.button("Zastosuj zmiany manualne", key="apply_manual"):
                    df = edited_df.copy()
                    st.success("Zastosowano zmiany manualne")
        
        with tab2:
            st.markdown("**Automatyczne zastÄ™powanie:**")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                replace_column = st.selectbox(
                    "Wybierz kolumnÄ™:",
                    df.columns.tolist(),
                    key="replace_column"
                )
            
            with col2:
                old_value = st.text_input("Stara wartoÅ›Ä‡:", key="old_value")
            
            with col3:
                new_value = st.text_input("Nowa wartoÅ›Ä‡:", key="new_value")
            
            if st.button("ZastÄ…p wartoÅ›ci", key="apply_replacement"):
                if replace_column and old_value:
                    count = (df[replace_column] == old_value).sum()
                    df[replace_column] = df[replace_column].replace(old_value, new_value)
                    st.success(f"ZastÄ…piono {count} wystÄ…pieÅ„ '{old_value}' na '{new_value}' w kolumnie '{replace_column}'")
        
        return df
    
    def _handle_scaling(self, df: pd.DataFrame) -> pd.DataFrame:
        """ObsÅ‚uguje skalowanie i standaryzacjÄ™"""
        st.subheader("Skalowanie i standaryzacja")
        
        # Pobierz wszystkie kolumny numeryczne z aktualnego DataFrame
        numeric_cols = get_numeric_columns(df)
        
        if not numeric_cols:
            st.warning("Brak kolumn numerycznych do skalowania.")
            return df
        
        st.info(f"Znalezione kolumny numeryczne: {', '.join(numeric_cols)}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            scaler_type = st.selectbox(
                "Wybierz metodÄ™ skalowania:",
                list(self.scalers.keys()),
                key="scaler_type"
            )
        
        with col2:
            cols_to_scale = st.multiselect(
                "Wybierz kolumny do skalowania:",
                numeric_cols,
                default=numeric_cols[:min(5, len(numeric_cols))],  # PokaÅ¼ wiÄ™cej domyÅ›lnie
                key="cols_to_scale"
            )
        
        if cols_to_scale and st.button("Zastosuj skalowanie", key="apply_scaling"):
            try:
                scaler = self.scalers[scaler_type]()
                df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])
                st.success(f"Zastosowano {scaler_type} dla {len(cols_to_scale)} kolumn: {', '.join(cols_to_scale)}")
            except Exception as e:
                st.error(f"BÅ‚Ä…d podczas skalowania: {str(e)}")
        
        return df
    
    def _handle_missing_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ObsÅ‚uguje brakujÄ…ce dane"""
        st.subheader("ObsÅ‚uga brakujÄ…cych danych")
        
        # SprawdÅº rÃ³Å¼ne oznaczenia brakÃ³w i skonwertuj je na NaN
        st.info("ðŸ” Sprawdzanie oznaczeÅ„ brakujÄ…cych danych...")
        
        # Lista moÅ¼liwych oznaczeÅ„ brakÃ³w
        missing_indicators = ['?', 'NA', 'N/A', 'null', 'NULL', '', ' ', 'nan', 'NaN', 'missing']
        
        # ZnajdÅº i skonwertuj rÃ³Å¼ne oznaczenia brakÃ³w
        original_missing_count = df.isnull().sum().sum()
        
        # ZamieÅ„ rÃ³Å¼ne oznaczenia brakÃ³w na NaN
        df_cleaned = df.copy()
        for indicator in missing_indicators:
            df_cleaned = df_cleaned.replace(indicator, np.nan)
        
        new_missing_count = df_cleaned.isnull().sum().sum()
        
        if new_missing_count > original_missing_count:
            st.success(f"ðŸ”§ Znaleziono i skonwertowano {new_missing_count - original_missing_count} dodatkowych oznaczeÅ„ brakÃ³w")
            df = df_cleaned
        
        # Informacje o brakujÄ…cych danych
        missing_info = df.isnull().sum()
        missing_cols = missing_info[missing_info > 0]
        
        if len(missing_cols) == 0:
            st.success("âœ… Brak brakujÄ…cych danych w zbiorze!")
            return df
        
        st.markdown("**Podsumowanie brakujÄ…cych danych:**")
        missing_summary_df = pd.DataFrame({
            'Kolumna': missing_cols.index,
            'Liczba brakÃ³w': missing_cols.values,
            'Procent brakÃ³w': (missing_cols.values / len(df) * 100).round(2)
        })
        st.dataframe(missing_summary_df, use_container_width=True, hide_index=True)
        
        # WyÅ›wietlanie szczegÃ³Å‚owych informacji o brakujÄ…cych danych
        st.markdown("**SzczegÃ³Å‚owe informacje o lokalizacji brakÃ³w:**")
        
        # ZnajdÅº wszystkie komÃ³rki z brakujÄ…cymi danymi
        missing_details = []
        
        for col in missing_cols.index:
            missing_mask = df[col].isnull()
            missing_indices = df[missing_mask].index.tolist()
            
            # Ogranicz wyÅ›wietlanie do pierwszych 20 indeksÃ³w
            indices_display = missing_indices[:20]
            if len(missing_indices) > 20:
                indices_str = f"{indices_display} ... (i {len(missing_indices) - 20} wiÄ™cej)"
            else:
                indices_str = str(missing_indices)
            
            missing_details.append({
                'Kolumna': col,
                'Typ kolumny': str(df[col].dtype),
                'Liczba brakÃ³w': len(missing_indices),
                'Indeksy z brakami': indices_str,
                'Procent': f"{(len(missing_indices) / len(df) * 100):.2f}%"
            })
        
        if missing_details:
            # Tabela z szczegÃ³Å‚ami brakÃ³w
            details_df = pd.DataFrame(missing_details)
            st.dataframe(details_df, use_container_width=True, hide_index=True)
            
            # ZnajdÅº wszystkie wiersze z jakimikolwiek brakami
            rows_with_any_missing = df[df.isnull().any(axis=1)]
            unique_missing_indices = sorted(rows_with_any_missing.index.tolist())
            
            st.markdown(f"**ðŸ“Š Podsumowanie:**")
            st.write(f"â€¢ **ÅÄ…czna liczba wierszy z brakami:** {len(unique_missing_indices)}")
            st.write(f"â€¢ **Procent wierszy z brakami:** {(len(unique_missing_indices) / len(df) * 100):.2f}%")
            st.write(f"â€¢ **Indeksy wierszy z brakami:** {unique_missing_indices}")
            
            # PokaÅ¼ prÃ³bkÄ™ wierszy z brakami
            if len(unique_missing_indices) > 0:
                st.markdown("**ðŸ“‹ PrÃ³bka wierszy z brakujÄ…cymi danymi:**")
                sample_size = min(10, len(unique_missing_indices))
                sample_missing = rows_with_any_missing.head(sample_size)
                
                # Dodaj kolumnÄ™ z oryginalnym indeksem
                sample_display = sample_missing.copy()
                sample_display.insert(0, 'Original_Index', sample_display.index)
                
                st.dataframe(sample_display, use_container_width=True, height=300)
                
                # Prosta mapa brakÃ³w
                st.markdown("**ðŸ—ºï¸ Mapa brakujÄ…cych danych (prÃ³bka):**")
                st.caption("âœ… = dane dostÄ™pne, âŒ = brak danych")
                
                # Konwertuj na mapÄ™ brakÃ³w
                missing_map = sample_missing.isnull()
                display_map = missing_map.copy()
                
                for col in display_map.columns:
                    display_map[col] = display_map[col].map({True: 'âŒ', False: 'âœ…'})
                
                display_map.insert(0, 'Index', sample_missing.index)
                st.dataframe(display_map, use_container_width=True, height=250)
        
        # Strategia obsÅ‚ugi brakÃ³w
        st.markdown("---")
        st.markdown("**ðŸ› ï¸ Wybierz strategiÄ™ obsÅ‚ugi brakÃ³w:**")
        
        strategy = st.radio(
            "Strategia:",
            ["UsuÅ„ wiersze z brakami", "UsuÅ„ kolumny z brakami", "WypeÅ‚nij braki"],
            key="missing_strategy"
        )
        
        if strategy == "UsuÅ„ wiersze z brakami":
            st.warning(f"âš ï¸ Ta operacja usunie {len(unique_missing_indices)} wierszy")
            if st.button("ðŸ—‘ï¸ UsuÅ„ wiersze z brakami", key="remove_rows_missing"):
                original_len = len(df)
                df = df.dropna()
                removed = original_len - len(df)
                st.success(f"âœ… UsuniÄ™to {removed} wierszy z brakujÄ…cymi danymi")
        
        elif strategy == "UsuÅ„ kolumny z brakami":
            cols_to_remove = st.multiselect(
                "Wybierz kolumny do usuniÄ™cia:",
                missing_cols.index.tolist(),
                key="cols_to_remove_missing"
            )
            if cols_to_remove:
                st.warning(f"âš ï¸ Ta operacja usunie kolumny: {cols_to_remove}")
                if st.button("ðŸ—‘ï¸ UsuÅ„ wybrane kolumny", key="remove_cols_missing"):
                    df = df.drop(columns=cols_to_remove)
                    st.success(f"âœ… UsuniÄ™to {len(cols_to_remove)} kolumn")
        
        else:  # WypeÅ‚nij braki
            col1, col2 = st.columns(2)
            
            with col1:
                fill_column = st.selectbox(
                    "Wybierz kolumnÄ™ do wypeÅ‚nienia:",
                    missing_cols.index.tolist(),
                    key="fill_column"
                )
            
            with col2:
                if fill_column in get_numeric_columns(df):
                    fill_method = st.selectbox(
                        "Metoda wypeÅ‚niania (kolumna numeryczna):",
                        ["Åšrednia", "Mediana", "WartoÅ›Ä‡ wÅ‚asna"],
                        key="fill_method"
                    )
                else:
                    fill_method = st.selectbox(
                        "Metoda wypeÅ‚niania (kolumna tekstowa):",
                        ["Moda", "WartoÅ›Ä‡ wÅ‚asna"],
                        key="fill_method_cat"
                    )
            
            if fill_method == "WartoÅ›Ä‡ wÅ‚asna":
                custom_value = st.text_input("Podaj wartoÅ›Ä‡ do wypeÅ‚nienia:", key="custom_fill_value")
            
            if st.button("ðŸ”§ WypeÅ‚nij braki", key="fill_missing"):
                missing_count = df[fill_column].isnull().sum()
                
                if fill_method == "Åšrednia":
                    fill_value = df[fill_column].mean()
                elif fill_method == "Mediana":
                    fill_value = df[fill_column].median()
                elif fill_method == "Moda":
                    mode_values = df[fill_column].mode()
                    fill_value = mode_values.iloc[0] if len(mode_values) > 0 else "Unknown"
                else:  # WartoÅ›Ä‡ wÅ‚asna
                    fill_value = custom_value
                
                if fill_value is not None:
                    df[fill_column] = df[fill_column].fillna(fill_value)
                    st.success(f"âœ… WypeÅ‚niono {missing_count} brakÃ³w w kolumnie '{fill_column}' wartoÅ›ciÄ…: {fill_value}")
                else:
                    st.error("âŒ Nie moÅ¼na wypeÅ‚niÄ‡ brakÃ³w - brak odpowiedniej wartoÅ›ci")
        
        return df
    
    def _handle_duplicates(self, df: pd.DataFrame) -> pd.DataFrame:
        """ObsÅ‚uguje duplikaty"""
        st.subheader("Usuwanie duplikatÃ³w")
        
        # Informacje o duplikatach
        duplicates_count = df.duplicated().sum()
        st.info(f"Znaleziono {duplicates_count} zduplikowanych wierszy")
        
        if duplicates_count > 0:
            # Opcje usuwania duplikatÃ³w
            subset_cols = st.multiselect(
                "Wybierz kolumny do sprawdzania duplikatÃ³w (puste = wszystkie):",
                df.columns.tolist(),
                key="duplicate_subset"
            )
            
            keep_option = st.selectbox(
                "KtÃ³re duplikaty zachowaÄ‡:",
                ["first", "last", "false"],
                format_func=lambda x: {"first": "Pierwszy", "last": "Ostatni", "false": "UsuÅ„ wszystkie"}[x],
                key="keep_duplicates"
            )
            
            if st.button("UsuÅ„ duplikaty", key="remove_duplicates"):
                original_len = len(df)
                subset = subset_cols if subset_cols else None
                keep = keep_option if keep_option != "false" else False
                
                df = df.drop_duplicates(subset=subset, keep=keep)
                removed = original_len - len(df)
                st.success(f"UsuniÄ™to {removed} duplikatÃ³w")
        
        return df
    
    def _handle_encoding(self, df: pd.DataFrame) -> pd.DataFrame:
        """ObsÅ‚uguje kodowanie kolumn symbolicznych"""
        st.subheader("Kodowanie kolumn symbolicznych")
        
        categorical_cols = get_categorical_columns(df)
        
        if not categorical_cols:
            st.info("Brak kolumn kategorycznych do kodowania.")
            return df
        
        col1, col2 = st.columns(2)
        
        with col1:
            encoding_method = st.selectbox(
                "Wybierz metodÄ™ kodowania:",
                ["One-Hot Encoding", "Binary Encoding", "Label Encoding"],
                key="encoding_method"
            )
        
        with col2:
            cols_to_encode = st.multiselect(
                "Wybierz kolumny do kodowania:",
                categorical_cols,
                key="cols_to_encode"
            )
        
        if cols_to_encode and st.button("Zastosuj kodowanie", key="apply_encoding"):
            if encoding_method == "One-Hot Encoding":
                df = self._apply_one_hot_encoding(df, cols_to_encode)
            elif encoding_method == "Binary Encoding":
                df = self._apply_binary_encoding(df, cols_to_encode)
            else:  # Label Encoding
                df = self._apply_label_encoding(df, cols_to_encode)
            
            st.success(f"Zastosowano {encoding_method} dla {len(cols_to_encode)} kolumn")
        
        return df
    
    def _apply_one_hot_encoding(self, df: pd.DataFrame, columns: list) -> pd.DataFrame:
        """Stosuje One-Hot Encoding"""
        for col in columns:
            dummies = pd.get_dummies(df[col], prefix=col)
            df = pd.concat([df, dummies], axis=1)
            df = df.drop(columns=[col])
        return df
    
    def _apply_binary_encoding(self, df: pd.DataFrame, columns: list) -> pd.DataFrame:
        """Stosuje Binary Encoding (uproszczona wersja)"""
        for col in columns:
            # Konwertuj na liczby
            le = LabelEncoder()
            encoded = le.fit_transform(df[col])
            
            # Konwertuj na binarny
            max_val = max(encoded)
            n_bits = len(bin(max_val)[2:])
            
            for i in range(n_bits):
                df[f"{col}_bit_{i}"] = [(x >> i) & 1 for x in encoded]
            
            df = df.drop(columns=[col])
        return df
    
    def _apply_label_encoding(self, df: pd.DataFrame, columns: list) -> pd.DataFrame:
        """Stosuje Label Encoding"""
        for col in columns:
            le = LabelEncoder()
            df[col] = le.fit_transform(df[col])
        return df
    
    def _show_comparison(self, original_df: pd.DataFrame, processed_df: pd.DataFrame):
        """Pokazuje porÃ³wnanie przed i po przetworzeniu"""
        st.subheader("ðŸ“Š PorÃ³wnanie przed/po")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            delta_rows = safe_metric_delta(len(processed_df) - len(original_df))
            st.metric(
                "Wiersze",
                len(processed_df),
                delta=delta_rows
            )
        
        with col2:
            delta_cols = safe_metric_delta(len(processed_df.columns) - len(original_df.columns))
            st.metric(
                "Kolumny",
                len(processed_df.columns),
                delta=delta_cols
            )
        
        with col3:
            processed_missing = processed_df.isnull().sum().sum()
            original_missing = original_df.isnull().sum().sum()
            delta_missing = safe_metric_delta(processed_missing - original_missing)
            st.metric(
                "BrakujÄ…ce wartoÅ›ci",
                processed_missing,
                delta=delta_missing
            )
        
        with col4:
            processed_duplicates = processed_df.duplicated().sum()
            original_duplicates = original_df.duplicated().sum()
            delta_duplicates = safe_metric_delta(processed_duplicates - original_duplicates)
            st.metric(
                "Duplikaty",
                processed_duplicates,
                delta=delta_duplicates
            )
        
        # PodglÄ…d przetworzonej tabeli
        if not processed_df.equals(original_df):
            st.markdown("**Przetworzone dane:**")
            st.dataframe(processed_df.head(10), use_container_width=True)